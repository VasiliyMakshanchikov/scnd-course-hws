{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fXydKdX6qzK7"
      },
      "source": [
        "**Homework_2**\n",
        "\n",
        "**Аналитика текста**\n",
        "\n",
        "⚡️Дата публикации: 12 февраля 2026 г.\n",
        "* ⏰ Срок сдачи без снижения: 23:59 MSK 1 марта 2026 г.\n",
        "* ⏰ Крайний срок сдачи: 23:59 MSK 15 марта 2026 г.\n",
        "\n",
        "После 23:59 MSK 1 марта 2026 г. оценка будет снижаться на 0,5 балла в день.\n",
        "Работы, сданные после крайнего срока, приниматься не будут.\n",
        "\n",
        "**Система оценивания**\n",
        "\n",
        "Решение оценивается по 10-балльной шкале, где:\n",
        "* **\"9-10\"** означает, что задание выполнено полностью, соблюдены все указанные требования по четырем частям.\n",
        "\n",
        "* Работа выполнена аккуратно и точно, без существенных замечаний;\n",
        "\n",
        "* Проведено дополнительное исследование и применены методы сегментации;\n",
        "\n",
        "* Подготовлена ​​презентация с сопроводительным письмом.\n",
        "\n",
        "* **\"8\"** — задание выполнено полностью, все четыре части домашнего задания выполнены:\n",
        "* Проведен анализ данных, предоставлен рабочий код и таблицы для анализа данных;\n",
        "\n",
        "* Представлены четкие выводы с подтверждающими данными (таблицы, графики).\n",
        "\n",
        "* 80% заданий выполнено\n",
        "\n",
        "* **\"6-7\"** — задание выполнено не полностью или имеет некоторые недостатки:\n",
        "* Проведен анализ данных, предоставлен рабочий код и таблицы для анализа данных;\n",
        "\n",
        "* Представлены четкие выводы с подтверждающими данными (таблицы, графики).\n",
        "\n",
        "* 60% заданий выполнено\n",
        "\n",
        "* **\"4-5\"** — задание выполнено со значительными недостатками:\n",
        "* Проведен анализ данных, предоставлен рабочий код и таблицы для анализа данных;\n",
        "\n",
        "* 40% заданий выполнено\n",
        "\n",
        "* **\"0-3\"** — задание не решено или решено неправильно.\n",
        "\n",
        "⚡️**Два идентичных или почти идентичных кода с выводами будут штрафоваться:\n",
        "0 баллов обоим студентам за задание, независимо от их результатов.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_kQYEp-gJGOC"
      },
      "source": [
        "\n",
        "# **Задача**\n",
        "\n",
        "## Часть 1: Анализ текста с помощью TF-IDF\n",
        "\n",
        "Цель:\n",
        "\n",
        "Изучить метод TF-IDF для векторизации текста\n",
        "Сравнить различные подходы к векторизации\n",
        "Провести статистический анализ текстовых данных\n",
        "\n",
        "## Часть 2: Классификация тональности с помощью BERT\n",
        "\n",
        "Задача:\n",
        "\n",
        "Цель этой задачи — использовать предварительно обученную модель BERT для классификации тональности рецензий на фильмы.\n",
        "\n",
        "## IMDB Dataset https://disk.yandex.ru/d/dhKpEgM4rQkLiQ;\n",
        "\n",
        "# **Задание для части 1:**\n",
        "\n",
        "**1. Рассчитайте метрику TF-IDF для любых трех песен на выбранном вами языке. (Вес задания: 30%)**\n",
        "\n",
        "**2. Сравните TF-IDF с другими методами векторизации текста, такими как Count Vectorizer, Word2Vec или Doc2Vec. (Вес задания: 30%)**\n",
        "\n",
        "**3. Проведите исследование, используя полученные преобразованные данные.\n",
        "Какие слова/фразы встречаются чаще всего, а какие реже. (Вес задания: 20%)**\n",
        "\n",
        "# **Задание для части 2:**\n",
        "\n",
        "**4. Используйте предварительно обученную модель BERT для\n",
        "классификации тональности отзывов о фильмах. (Вес задания: 20%)**\n",
        "\n",
        "⚡️Все комментарии, описания сегментов и выводы по домашнему заданию можно вносить непосредственно в блокнот с кодом.\n",
        "\n",
        "# **Описание задания**\n",
        "**1. Рассчитайте метрику TF-IDF для любых трех песен на одном языке по вашему выбору. (Вес задачи: 30%)**\n",
        "\n",
        "Исследование распределения данных:\n",
        "* ✅ 1. Подготовка данных:\n",
        "* Выберите 3 песни на одном языке\n",
        "* Переработка текста:\n",
        "\n",
        "* Преобразование в нижний регистр\n",
        "* Удаление стоп-слов\n",
        "\n",
        "* Лемматизация/стемминг\n",
        "* Токенизация\n",
        "\n",
        "* ✅ 2. Реализация TF-IDF:\n",
        "\n",
        "* Использование\n",
        "\n",
        "* sklearn.feature_extraction.text\n",
        "\n",
        "* Расчет матрицы TF-IDF\n",
        "\n",
        "* Визуализация результатов\n",
        "\n",
        "Результаты части 1:\n",
        "* ✅ Таблицы, сводные отчеты и графики (например, гистограммы и диаграммы «ящик с усами»);\n",
        "\n",
        "* ✅ Все данные должны сопровождаться выводами, основанными на полученных результатах исследования (3-4 предложения);\n",
        "\n",
        "* ✅ Данные подготовлены для сравнения с другими методами векторизации.\n",
        "\n",
        "Снижение оценки:\n",
        "* Слишком много таблиц и графиков без пояснений;\n",
        "\n",
        "* Недостаточная очистка данных — стоп-слова не были удалены;\n",
        "\n",
        "* Сводные таблицы и графики без сортировки;\n",
        "\n",
        "**2. Сравните TF-IDF с другими методами векторизации текста, такими как Count Vectorizer, Word2Vec или Doc2Vec. (Вес задачи: 30%)**\n",
        "\n",
        "⚡️Критерии сравнения:\n",
        "* Вычислительная сложность\n",
        "* Качество представления\n",
        "* Интерпретируемость\n",
        "\n",
        "Результат части 2:\n",
        "* ✅ Было проведено сравнение трех методов векторизации в соответствии с указанными критериями сравнения;\n",
        "\n",
        "Снижение оценки:\n",
        "* Избыточное количество таблиц и графиков без пояснений;\n",
        "* Реализовано менее трех методов;\n",
        "* Не все критерии сравнения реализованы;\n",
        "\n",
        "**3. Проведите исследование, используя полученные преобразованные данные.\n",
        "\n",
        "Какие слова/фразы встречаются чаще всего, а какие реже (вес задачи: 20%)**\n",
        "\n",
        "Результаты части 3:\n",
        "Выполнен статистический анализ текста;\n",
        "\n",
        "* ✅ Выполнен статистический анализ текста;\n",
        "* Отображение 10 наиболее часто встречающихся слов;\n",
        "* Отображение 10 наиболее часто встречающихся сочетаний слов;\n",
        "* ✅ Графическая визуализация (t-sne, WordCloud);\n",
        "\n",
        "Выводы:\n",
        "* Нет выводов относительно сравнения;\n",
        "* Графики/таблицы не сравнивались;\n",
        "\n",
        "**4. Используйте предварительно обученную модель BERT для\n",
        "классификации тональности отзывов о фильмах. (Вес задачи: 20%)**\n",
        "\n",
        "\n",
        "Execution algorithm::\n",
        "* ✅ 1.Data preparation:\n",
        "*   Loading IMDB Dataset https://disk.yandex.ru/d/dhKpEgM4rQkLiQ;\n",
        "*   Text Preprocessing;\n",
        "*   Train/Test Split;\n",
        "* ✅ 2. Работа с BERT:\n",
        "* Загрузите предварительно обученную модель BERT и соответствующий ей токенизатор с сайта Hugging Face:\n",
        "* Hugging Face Transformers\n",
        "* Токенизация\n",
        "* Создание классификатора\n",
        "* Подготовка данных: используйте токенизатор BERT для преобразования текстов в формат входных данных модели (входные идентификаторы, маски внимания и т. д.).\n",
        "\n",
        "* ✅ 3. Обучение модели BERT:\n",
        "* Тонкая настройка BERT: обучите модель на обучающем наборе данных и оцените ее качество на тестовом наборе данных;\n",
        "* Оценка метрик:\n",
        "* Точность\n",
        "* Точность/Полнота\n",
        "* F1-мера\n",
        "\n",
        "Результаты части 4:\n",
        "* ✅ Точность на тестовом наборе данных не ниже заданного порогового значения (например, 0,9).\n",
        "* ✅ F1-мера для положительного класса близка к точности, что указывает на баланс между точностью и полнотой.\n",
        "* ✅ Модель корректно различает явно положительные и явно отрицательные отзывы при ручной проверке примеров.\n",
        "* ✅ Результаты стабильны при повторном разделении на обучающую и тестовую выборки (значительного снижения показателей не наблюдается).\n",
        "* ✅ Время вывода на один отзыв достаточно короткое для практического использования (например, доли секунды на типичном GPU/CPU).\n",
        "* ✅ Алгоритм обучения модели на основе задачи завершен;\n",
        "* ✅ Все данные должны сопровождаться выводами, основанными на полученных результатах исследования (2-3 предложения);\n",
        "\n",
        "Сниженная оценка:\n",
        "* Модель не из Hugging Face / не BERT / не предварительно обучена;\n",
        "* Отсутствует отдельная загрузка токенизатора или используется неправильный;\n",
        "* Код существует, но не запускается из-за незначительных ошибок (импорт, имя модели);\n",
        "* Тексты не токенизированы токенизатором BERT;\n",
        "* Поля Input_ids и attention_mask (или аналогичные обязательные поля) не генерируются;\n",
        "* Некорректные параметры токенизации (например, отсутствует заполнение/обрезка при необходимости);\n",
        "* Отсутствует дополнительный линейный слой для бинарной классификации;\n",
        "* Линейный слой присутствует, но количество выходов указано неверно / отсутствует активация на выходе при вычислении прогнозов;\n",
        "* Модель вообще не обучалась;\n",
        "* Отсутствует разделение между обучающим и тестовым наборами данных;\n",
        "* Не выполняется расчет указанных метрик (точность, F1 или аналогичные);\n",
        "* Метрики рассчитываются некорректно (например, на основе обучающих данных или из-за ошибки в коде);\n",
        "* Код полностью идентичен примеру или работам других студентов.\n",
        "\n",
        "# **Отправка результатов:**\n",
        "\n",
        "* Отправьте домашнее задание через форму Яндекса в виде ссылки на ваш GitHub, где будут находиться все файлы и код (Python).\n",
        "* GitHub должен быть открыт, а код должен работать без ошибок.\n",
        "* Назовите репозиторий, используя шаблон (HW_2_2025-Имя_Фамилия).\n",
        "* Ссылка на форму Яндекса: https://forms.yandex.ru/u/692f511f505690b43617e5a3\n",
        "\n",
        "# **Дополнительные материалы для домашнего задания:**\n",
        "\n",
        "* Пример анализа текстовых данных, обсуждавшийся на семинаре, как пример решения домашнего задания: https://colab.research.google.com/drive/1zD3NCuSORsg1BJEo5HSw7LtEzzMJ9nP4?usp=sharing;\n",
        "\n",
        "* Анализ настроений с помощью обученного BERT (hugging face), обсуждавшийся на семинаре:\n",
        "https://colab.research.google.com/drive/1vC8XoAeLRqBhth1aWTqmi9RlxDJP4Ol7?usp=sharing\n",
        "* Пример описания исследовательской работы в формате презентации — шпаргалка для домашнего задания предоставлена ​​в папке с опциями: https://disk.yandex.ru/d/HK53_fe77k4rvA;\n",
        "\n",
        "\n",
        "# GUI:\n",
        "* https://desktop.github.com/\n",
        "* https://git-scm.com/\n",
        "* https://tortoisegit.org/\n",
        "\n",
        "# Resources:\n",
        "* * https://git-scm.com/book/ru/v2\n",
        "* http://www-cs-students.stanford.edu/~blynn/gitmagic/intl/ru/\n",
        "* https://guides.github.com/activities/hello-world/\n",
        "\n",
        "Interactive tours: https://githowto.com/ru\n",
        "* https://learngitbranching.js.org/?locale=ru_RU\n",
        "\n",
        "\n",
        "# Useful links on each topic:\n",
        "# **Занятие 4 Инструменты и методы текстовой аналитики**\n",
        "* https://docs.google.com/presentation/d/1PY_JeAuRFdPkneEnpSaNAf6PYmO-waLABTHJcjvXEn0/edit?slide=id.g31d89f3c299_0_319#slide=id.g31d89f3c299_0_319\n",
        "\n",
        "# **Занятие 5 Инструменты и методы текстовой аналитики**\n",
        "* https://docs.google.com/presentation/d/1BOAZXyQAWgMoLQwcxDfIqYQB_BXNOsr5JQSzedk4G_g/edit?usp=sharing\n",
        "\n",
        "# **List of literature**\n",
        "\n",
        "* Converting text data and working with it in Python. URL:\n",
        "    *    https://academy.yandex.ru/handbook/data-analysis/article/preobrazovanie-tekstovyh-dannyh-i-ra  bota-s-nimi-v-python\n",
        "\n",
        "* Basics of Natural Language Processing for text. URL:  \n",
        "    *   https://habr.com/ru/companies/Voximplant/articles/446738/\n",
        "\n",
        "* The Natasha project. A set of high-quality open-source tools for natural Russian language processing (NLP). URL:\n",
        "    *   https://habr.com/ru/articles/516098/\n",
        "\n",
        "* Natasha Library. URL:\n",
        "    *   https://natasha.github.io/\n",
        "\n",
        "* Repository of a course on text analysis and natural language processing at the MIPT FIVT.  URL:\n",
        "    *   https://github.com/andybelov/nlp_mipt\n",
        "\n",
        "* Your guide to the world of NLP (Natural Language Processing). URL:  \n",
        "    *   https://habr.com/ru/companies/otus/articles/705482/\n",
        "\n",
        "* Introduction to Natural Language Processing. URL:\n",
        "    *   https://stepik.org/course/1233/syllabus\n",
        "\n",
        "* Morphological analyzer pymorphy2. URL:  \n",
        "    *   https://pymorphy2.readthedocs.io/en/stable/\n",
        "\n",
        "* Bolshakova E. I. AUTOMATIC TEXT PROCESSING IN NATURAL LANGUAGE AND COMPUTER LINGUISTICS. URL:    \n",
        "    *   https://www.hse.ru/data/2012/04/05/1251263483/пособие%20школа%20по%20компьютерной%20linguistics%20 - %20 copy.pdf\n",
        "* Let's create an Intelligent Chatbot. URL:  \n",
        "    *   https://machinelearningmastery.ru/lets-build-an-intelligent-chatbot-7ea7f215ada6/\n",
        "\n",
        "* The Illustrated BERT, ELMo, and co. URL:\n",
        "    *   https://jalammar.github.io/illustrated-bert/\n",
        "\n",
        "* BERT (языковая модель). URL:\n",
        "    *   https://neerc.ifmo.ru/wiki/index.php?title=BERT_(языковая_модель)\n",
        "\n",
        "* BERT, ELMO и Ко в картинках (как в NLP пришло трансферное обучение).    \n",
        "    *   https://habr.com/ru/articles/487358/\n",
        "\n",
        "* BERT for \"Everyone\" (Tutorial + Implementation). URL:\n",
        "    *   https://www.kaggle.com/code/harshjain123/bert-for-everyone-tutorial-implementation\n",
        "\n",
        "* Как использовать BERT для мультиклассовой классификации текста. URL:\n",
        "    *   https://neurohive.io/ru/tutorial/bert-klassifikacya-teksta/\n",
        "\n",
        "# **Pre-trained modules**\n",
        "* Hugging Face, bert-base-uncased. URL:\n",
        "    *   https://huggingface.co/bert-base-uncased\n",
        "\n",
        "* BERT in DeepPavlov. URL:\n",
        "    *   http://docs.deeppavlov.ai/en/master/features/models/bert.html\n",
        "* BERT и Hugging face:\n",
        "    *   https://colab.research.google.com/drive/1vC8XoAeLRqBhth1aWTqmi9RlxDJP4Ol7?usp=sharing\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
